{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a913dfb-2ea7-40c4-83ae-49cabc7ff66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.910, loss: 0.192\n",
      "0.91\n",
      "0.92\n",
      "validation, acc: 0.920, loss: 0.170\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold\n",
    "%run Full_Neural_Network.ipynb\n",
    "\n",
    "#loading in dataframe\n",
    "df = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
    "#convert to numpy\n",
    "data = df.to_numpy()\n",
    "#shuffle data\n",
    "np.random.shuffle(data)\n",
    "#randomly choose 100 examples with no replacement\n",
    "training_data = data[np.random.choice(data.shape[0], 100, replace=False)]\n",
    "#setup training data\n",
    "labels_array = training_data[:, -1]\n",
    "labels_array = labels_array.astype(int)\n",
    "features = training_data[:, :-1]\n",
    "\n",
    "\n",
    "\n",
    "dense1 = Layer_Dense(12, 64, weight_regularizer_l2=0.0009, bias_regularizer_l2=0.0009)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(64, 2)\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "optimizer = Optimizer_Adam(learning_rate=0.001, decay=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(100001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(features)\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    data_loss = loss_activation.forward(dense2.output, labels_array)\n",
    "    # Calculate regularization penalty\n",
    "    regularization_loss = \\\n",
    "    loss_activation.loss.regularization_loss(dense1) + \\\n",
    "    loss_activation.loss.regularization_loss(dense2)\n",
    "    # Calculate overall loss\n",
    "    loss = data_loss + regularization_loss\n",
    "    # Calculate accuracy from output of activation2 and targets # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(labels_array.shape) == 2:\n",
    "        labels_array = np.argmax(labels_array, axis=1) \n",
    "    accuracy = np.mean(predictions==labels_array)\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, labels_array)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()\n",
    "    if epoch == 100000:\n",
    "        print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')\n",
    "print(accuracy)\n",
    "\n",
    "testing_data = data[np.random.choice(data.shape[0], 100, replace=False)]\n",
    "testing_labels = training_data[:, -1]\n",
    "testing_labels = testing_labels.astype(int)\n",
    "testing_features = training_data[:, :-1]\n",
    "\n",
    "dense1.forward(testing_features)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "loss = loss_activation.forward(dense2.output, testing_labels)\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(testing_labels.shape) == 2:\n",
    "    testing_labels = np.argmax(testing_labels, axis=1) \n",
    "accuracy = np.mean(predictions == testing_labels)\n",
    "print(accuracy)\n",
    "print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78002ca5-6186-419d-bd26-5e0cc8164bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.990, loss: 0.062\n",
      "0.99\n",
      "Layer Widths: 64  Learning Rate: .001\n",
      "validation, acc: 0.820, loss: 1.616\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold\n",
    "%run Full_Neural_Network.ipynb\n",
    "\n",
    "#loading in dataframe\n",
    "df = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
    "#convert to numpy\n",
    "data = df.to_numpy()\n",
    "#shuffle data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "#randomly choose 100 examples with no replacement\n",
    "training_data = data[np.random.choice(data.shape[0], 100, replace=False)]\n",
    "\n",
    "#setup training data\n",
    "trainLabels = training_data[:, -1]\n",
    "trainLabels = trainLabels.astype(int)\n",
    "trainFeatures = training_data[:, :-1]\n",
    "\n",
    "#setup layerDense1\n",
    "dense1 = Layer_Dense(12, 64, weight_regularizer_l2 = 0.0009, bias_regularizer_l2 = 0.0009)\n",
    "#setup Relu1\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(64, 2)\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "optimizer = Optimizer_Adam(learning_rate= 0.001, decay=5e-4)\n",
    "\n",
    "for epoch in range(100001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(trainFeatures)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    data_loss = loss_activation.forward(dense2.output, trainLabels)\n",
    "    regularization_loss = loss_activation.loss.regularization_loss(dense1) + loss_activation.loss.regularization_loss(dense2)\n",
    "    loss = data_loss + regularization_loss\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    accuracy = np.mean(predictions==trainLabels)\n",
    "\n",
    "\n",
    "    loss_activation.backward(loss_activation.output, trainLabels)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()\n",
    "    if epoch == 100000:\n",
    "        print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')\n",
    "\n",
    "print(accuracy)\n",
    "    \n",
    "    \n",
    "testing_data = data[np.random.choice(data.shape[0], 100, replace=False)]\n",
    "testing_labels = training_data[:, -1]\n",
    "testing_labels = testing_labels.astype(int)\n",
    "testing_features = training_data[:, :-1]\n",
    "\n",
    "dense1.forward(testing_features)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "loss = loss_activation.forward(dense2.output, testing_labels)\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(testing_labels.shape) == 2:\n",
    "    testing_labels = np.argmax(testing_labels, axis=1) \n",
    "accuracy = np.mean(predictions == testing_labels)\n",
    "print(accuracy)\n",
    "print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')\n",
    "\n",
    "###############\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d9e4ce-7d1d-4ee6-84ef-2d567b1aaf54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.930, loss: 0.208\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "df = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
    "data = df.to_numpy()\n",
    "np.random.shuffle(data)\n",
    "training_data = data[np.random.choice(data.shape[0], 100, replace=False)]\n",
    "labels_array = training_data[:, -1]\n",
    "labels_array = labels_array.astype(int)\n",
    "features = training_data[:, :-1]\n",
    "\n",
    "\n",
    "\n",
    "dense1 = Layer_Dense(12, 64, weight_regularizer_l2=0.0009, bias_regularizer_l2=0.0009)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(64, 2)\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "optimizer = Optimizer_Adam(learning_rate=0.001, decay=5e-4)\n",
    "# Train in loop\n",
    "for epoch in range(100001):\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(features)\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    data_loss = loss_activation.forward(dense2.output, labels_array)\n",
    "    # Calculate regularization penalty\n",
    "    regularization_loss = \\\n",
    "    loss_activation.loss.regularization_loss(dense1) + \\\n",
    "    loss_activation.loss.regularization_loss(dense2)\n",
    "    # Calculate overall loss\n",
    "    loss = data_loss + regularization_loss\n",
    "    # Calculate accuracy from output of activation2 and targets # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(labels_array.shape) == 2:\n",
    "        labels_array = np.argmax(labels_array, axis=1) \n",
    "    accuracy = np.mean(predictions==labels_array)\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, labels_array)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()\n",
    "\n",
    "\n",
    "testing_data = data[np.random.choice(data.shape[0], 100, replace=False)]\n",
    "testing_labels = training_data[:, -1]\n",
    "testing_labels = testing_labels.astype(int)\n",
    "testing_features = training_data[:, :-1]\n",
    "dense1.forward(testing_features)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "loss = loss_activation.forward(dense2.output, testing_labels)\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(testing_labels.shape) == 2:\n",
    "    testing_labels = np.argmax(testing_labels, axis=1) \n",
    "accuracy = np.mean(predictions == testing_labels)\n",
    "print(f'validation, acc: {accuracy:.3f}, loss: {loss:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
